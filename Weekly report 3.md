# Weekly Report 3

**Oct.21** 

## Paper Reading

### Attention is all you need

#### motivation

- ä¼ ç»ŸRNNæ–¹æ³•éœ€è¦è€ƒè™‘é¡ºåºï¼Œä¸èƒ½å¾ˆå¥½çš„å¹¶è¡Œè®¡ç®—
- å­¦ä¹ è¿œè·ç¦»ä¹‹é—´çš„å…³ç³»ä¼šå¾ˆå›°éš¾ï¼ˆå‚æ•°é‡éšç€ä½ç½®è·ç¦»å¢žåŠ è€Œå¢žåŠ ï¼‰

#### Model Architecture

![The Transformer - model architecture](https://i.stack.imgur.com/eAKQu.png)

##### Dot-Product Attention

$$
Attention(Q,K,V)=softmax(\frac{QK^T}{\sqrt{d_k}}ï¼‰V
$$

Qï¼ŒKä»£è¡¨queriesï¼Œkeysï¼Œå…¶å†…å®¹ä¸ºä¸€ç»„$d_k$ç»´å‘é‡å †å çš„çŸ©é˜µã€‚Vä¸ºvaluesï¼Œæ˜¯ä¸€ç»„$d_v$ç»´å‘é‡å †å çš„çŸ©é˜µã€‚

##### Multi-Head Attention

$$
MultiHead(Q,K,V)=Concat(head_1,...,head_h)W^O\\
where \ head_i = Attention(QW_i^Q, KW_i^K, VW_i^V)
$$

å…¶ä¸­æŠ•å½±çŸ©é˜µ$W_i^Q \in \mathbb{R}^{d_{model}\times d_k}, W_i^K \in \mathbb{R}^{d_{model}\times d_k}, W_i^V \in \mathbb{R}^{d_{model}\times d_v}\ and W_i^Q \in \mathbb{R}^{hd_v\times d_{model}}$



##### Feed-Forward Networks

attentionå±‚åŽæ¯ä¸ªä½ç½®éƒ½æ·»åŠ æœ‰ç›¸åŒçš„å…¨è¿žæŽ¥feed-forwardç½‘ç»œã€‚
$$
FFN(x)=\max(0, xW_1+b_1)W_2+b_2
$$

##### Positional Encoding

æ²¡æœ‰RNNï¼ŒCNNæ‰€ä»¥å¤±åŽ»äº†ä½ç½®ä¿¡æ¯ï¼Œé€šè¿‡æ·»åŠ positional encodingæ¥ç»™ç½‘ç»œæä¾›ä½ç½®ä¿¡æ¯ã€‚
$$
PE_{(pos,2i)}=\sin(\frac{pos}{10000^{2i/d_{model}}}) \\
PE_{(pos,2i+1)}=\cos(\frac{pos}{10000^{2i/d_{model}}})
$$
$pos$ä¸ºä½ç½®ï¼Œ$i$ä¸ºç»´åº¦ã€‚é€šè¿‡åŠ å’Œçš„æ–¹å¼ç›´æŽ¥åŠ å…¥input embeddingï¼ˆä¿è¯ä½ç½®ä¿¡æ¯ä¸Žå…¶ç»´åº¦ç›¸åŒï¼‰



### ViT

> An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale

#### Motivation

- Transformerç»“æž„åœ¨NLPä¸Šé¢å‘å±•ä¸é”™ï¼Œä½†åœ¨è®¡ç®—æœºè§†è§‰è¿˜æœ‰å¾ˆå¤šå±€é™ã€‚
- æ²¡å¿…è¦ä¾èµ–CNNï¼Œçº¯transformerç”¨äºŽå›¾åƒåˆ†ç±»ä¹Ÿåº”è¯¥æ€§èƒ½ä¼˜å¼‚ã€‚

#### Model Architecture

![ViT Model overview](https://github.com/lucidrains/vit-pytorch/raw/main/images/vit.gif)

##### inputå¤„ç†

æ ‡å‡†transformeræŽ¥å—ä¸€ç»´tokenï¼Œä¸ºäº†å¤„ç†äºŒç»´çš„å›¾åƒä¿¡æ¯ï¼ŒæŠŠå›¾åƒreshapeï¼š$x\in \mathbb{R}^{H\times W\times C} \to x_p \in \mathbb{R}^{N\times(P^2 \cdot C)}$å…¶ä¸­$P$ä¸ºåˆ†å‰²åŽå›¾ç‰‡å°ºå¯¸ï¼›$N=HW/P^2$ä»£è¡¨åˆ†å‰²åŽå›¾ç‰‡åˆ†å—æ•°é‡ï¼ŒåŒæ—¶ä¹Ÿæ˜¯è¾“å…¥Tranformerçš„åºåˆ—é•¿åº¦ã€‚ç”±äºŽTransformerä½¿ç”¨æ½œåœ¨å‘é‡ç»´åº¦Dï¼Œæ‰€ä»¥éœ€è¦æŠŠå›¾ç‰‡æ‹‰å¹³åŽæŠ•å½±ä¸ºDç»´åº¦å‘é‡å†è¾“å…¥ã€‚

##### Patch + Position embedding

$$
\begin{align}
z_0 &= [x_{class};x^1_pE;x^2_pE;\cdots;x^N_pE]+E_{pos},  &&E\in\mathbb{R}^{(P^2\cdot C)\times D} ,E_{pos}\in\mathbb{R}^{(N+1)\times D} \\
z'_l &=MSA(LN(z_{l-1}))+z_{l-1}, &&l=1\dots L \\
z_l &=MLP(LN(z'_{l}))+z'_{l}, &&l=1\dots L \\
y &= LN(z^0_L)
\end{align}
$$

å…¶ä¸­$LN$ä¸ºLayernormï¼Œ

åœ¨æ‰€æœ‰åˆ†å—åºåˆ—embeddingä¹‹å‰æ·»åŠ äº†ä¸€ä¸ªå¯å­¦ä¹ çš„embeddingï¼ˆ$z^0_0=x_{class}$ï¼‰,å®ƒé€šè¿‡transformeråŽçš„è¾“å‡ºçŠ¶æ€ï¼ˆ$z^0_L$ï¼‰ç”¨ä½œå›¾åƒè¡¨ç¤º$y$ã€‚

## Concepts

### Generative model & Discriminative model

![discriminative_vs_generative](https://duphan.files.wordpress.com/2016/09/discriminative_vs_generative.png?w=1100)

å…ˆå®šä¹‰å‡ ä¸ªç¬¦å·æ„æ€ï¼š

- $P(C_i)$: åœ¨æ•°æ®é›†ä¸­$C_i$ç±»æ•°æ®æ‰€å çš„æ¯”çŽ‡
- $P(x|C_i)$: åœ¨æ•°æ®é›†ä¸­$C_i$ç±»ä¸­ï¼ŒæŸä¸ªæ•°æ®xå±žäºŽ$C_i$çš„æ¦‚çŽ‡
- $P(C_i|x)$: æŸä¸ªæ•°æ®xï¼Œå±žäºŽæ•°æ®é›†ä¸­$C_i$ç±»çš„æ¦‚çŽ‡ï¼ˆæœ€ç»ˆç›®çš„ï¼‰

#### Discriminative model

Discriminative modelä¸ç®¡å…¶ä»–åˆ†å¸ƒï¼Œç›´æŽ¥å¯¹$P(C_i|x)$å»ºæ¨¡ã€æ±‚è§£ã€‚ä»¥ä¸€ä¸ªä¸€å±‚ç¥žç»ç½‘ç»œä¸ºä¾‹ï¼š

è®¾æ¨¡åž‹å‚æ•°ä¸º$w, b$ï¼Œåˆ™$P(C_i|x)=sigmoid(wx+b)$ï¼Œå†å¯¹$C_i$æ‰“ä¸Š1/0æ ‡ç­¾ï¼Œé€šè¿‡æŸå¤±å‡½æ•°è®­ç»ƒå¾—åˆ°æ¨¡åž‹å‚æ•°$w, b$ã€‚

å¦‚æžœ$P(C_i|x)=\max_{j=1}^{n}{P(C_j|x)}$ï¼Œåˆ™åˆ¤å®šxå±žäºŽ$C_i$ç±»ã€‚

#### Generative model

Generative Modelä¼šå…ˆå‡å®š$C_i$åˆ†å¸ƒæ¨¡åž‹ï¼Œå†è®¡ç®—xå±žäºŽ$C_i$çš„æ¦‚çŽ‡ï¼Œä»Žè€Œç¡®å®šxçš„ç±»åˆ«æ¦‚çŽ‡ã€‚

##### å‡å®š$C_i$åˆ†å¸ƒ

ä¸€èˆ¬æ¥è¯´æˆ‘ä»¬æŠŠå®ƒå‡å®šä¸ºé«˜æ–¯åˆ†å¸ƒï¼Œå› ä¸ºé«˜æ–¯åˆ†å¸ƒæ¨¡åž‹å‚æ•°å¥½è®¡ç®—ï¼Œè€Œä¸”å¤§è‡ªç„¶ä¸­å¾ˆå¸¸è§ã€‚é«˜æ–¯åˆ†å¸ƒä¸ºï¼š
$$
f(x)=\frac{1}{\sigma \sqrt{2\pi}}e^{-\frac{1}{2}(\frac{x-\pi}{\sigma})^2}
$$

##### è®¡ç®—æ¨¡åž‹å‚æ•°

å¯¹äºŽé«˜æ–¯åˆ†å¸ƒè€Œè¨€ï¼Œå…¶å‡å€¼å’Œæ–¹å·®æ»¡è¶³å¦‚ä¸‹å…¬å¼ï¼š
$$
\mu^* = \frac{1}{n}\sum_{i=1}^n x_i; \quad \Sigma^*=\frac{1}{n}\sum_{i=1}^n (x_i-\mu^*)(x_i-\mu^*)^T
$$
æ‰€ä»¥æˆ‘ä»¬å¾—åˆ°äº†$C_i$åˆ†å¸ƒçš„å‚æ•°$\mu_i\in C^n, \Sigma_i\in C^{n\times n}$ï¼Œå³$C_i \sim N(\mu_i,\Sigma_i)$ï¼ˆå¤šå…ƒé«˜æ–¯åˆ†å¸ƒï¼‰

##### è®¡ç®—æ¦‚çŽ‡å¹¶åˆ†ç±»

å¸¦å…¥å¤šå…ƒé«˜æ–¯åˆ†å¸ƒå‡½æ•°ä¸­å¯å¾—xå±žäºŽ$C_i$çš„æ¦‚çŽ‡åˆ†å¸ƒ:
$$
P(x|C_i)=\frac{1}{(2\pi)^{D/2}}\frac{1}{|\Sigma_i|^{1/2}}exp\{-\frac{1}{2}(x-\mu_i)^T\Sigma^{-1}(x-\mu_i)\}
$$
å…¶ä¸­ï¼ŒDä¸ºå‘é‡xçš„ç»´åº¦ï¼Œ$\Sigma$ä»£è¡¨å˜é‡ X çš„åæ–¹å·®çŸ©é˜µï¼Œ iè¡Œjåˆ—çš„å…ƒç´ å€¼è¡¨ç¤º$ð‘¥_i$ä¸Ž$ð‘¥_j$çš„åæ–¹å·®ã€‚

æœ‰äº†$P(C_i),P(x|C_i)$å°±å¯ä»¥è®¡ç®—$P(C_i|x)$:
$$
P(C_i|x)=\frac{P(C_i)P(x|C_i)}{\sum_{j=1}^{n}P(C_j)P(x|C_j)}
$$
è¿™ä¹Ÿæ˜¯è´å¶æ–¯å…¬å¼ã€‚

æœ€åŽ$P(C_i|x)=\max_{j=1}^{n}{P(C_j|x)}$ï¼Œåˆ™åˆ¤å®šxå±žäºŽ$C_i$ç±»ã€‚

## torch

### einopsåŒ…

> æ•°æ®å¤„ç†ç»´åº¦å¤„ç†åŒ…ï¼Œåˆ†å‰²ï¼Œæ‹‰å¹³ç­‰æ“ä½œ

å®‰è£…

```sh
pip install einops
```

usage

```python
import torch
from einops import rearrange

y = x.transpose(0, 2, 3, 1)
# æ”¹ä¸º
y = rearrange(x, 'b c h w -> b h w c')

# Flattenæ“ä½œ
x = torch.randn(64, 3, 16, 16)
y = rearrange(x, 'b c h w -> b (c h w)')
# out: y.shape: torch.Size([64, 768])

# å›¾ç‰‡åˆ‡åˆ†é‡æ‹æ“ä½œ
x = torch,randn(1, 3, 256, 256)
patch_height = 16
patch_width = 16
# å°†å›¾ç‰‡æ‹†åˆ†æˆ16
# x:[b, c, h, w] -> y:[b, N, p^2c]
y = rearrange(x, 'b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1=patch_height, p2=patch_width)
```

